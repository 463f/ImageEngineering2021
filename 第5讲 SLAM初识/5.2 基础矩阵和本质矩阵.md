# 5.2 基础矩阵和本质矩阵

# 1. 基础矩阵

　　假设相机在运动过程中在 $O_{1,2}$ 处得到了两张图像，如下图

　　![对极几何示意图](assets/image-20211102220300-9ib6uca.png "对极几何示意图")

　　相机从 $O_1$ 到 $O_2$ 假设有单应矩阵 $H_{\pi}$ ，因为这是从平面到平面的关系，所以为单应矩阵。而基本矩阵 $F$ 的作用是把点 $P_1$ 和 $P_2$ 关联起来。

$$
\begin{align}
p_2 = H_{\pi} \cdot p_1
\end{align}
$$

　　我们根据叉乘写出直线 $l_2$ 的表达式：$e_2 \times p_2 = e_2 \times H_{\pi} p_1$ ，又因为 $p_2$ 在 $l_2$ 上，所以有 $p_2^Tl_2 = 0$ ，在式子的左右两侧乘以 $p_2^T$ ，可得：

$$
\begin{align}
p_2^T e_2 \times H_{\pi} p_1 &= p_2^T \cdot [e_2]_{\text{x}} H_{\pi} \cdot p_1 = p_2^T \cdot F \cdot p_1 = 0 \\
F =& [e_2]_{\text{x}} H_{\pi}
\end{align}
$$

　　上式中的 $F$ 称为基础矩阵，它包含内参（单应矩阵中有内参），而本质矩阵 $E$ 的作用是把内参去掉，只留下外参。

# 2. 本质矩阵

　　如果把相机 $O_1$ 作为世界坐标系（即相机坐标系和世界坐标系重合），那么对于

$$
\begin{align}
p_1 &= K_1 \cdot p
\\
\therefore p &= K_1^{-1} p_1
\end{align}
$$

　　从 $O_1$ 到 $O_2$ 就是刚体变换，所以我们把 P 的坐标从 $O_1$ 转换到 $O_2$ 中，转换过程就是世界坐标系到相机坐标系的 RT 矩阵。

$$
\begin{align}
p_2 &= K_2 (R p+ t) \\
p_2 &= K_2 (R K_1^{-1}p_1 + t) \\
K_2^{-1}p_2 &= R K_1^{-1}p_1 + t
\end{align}
$$

　　这里我们认为两个相机的内参是不同的，如果是同一个相机（单目视觉运动）那么内参便是相同的。

　　因为我们上面推导基础矩阵时得到了 $p_2^T \cdot F \cdot p_1 = 0$ 这个表达式，下面我们也要往这个形式靠近。我们把 $P_{1, 2}$ 的坐标归一化，写为 $x_{1,2}$ ，那么有

$$
\begin{align}
 x_1 &= K_1^{-1}p_1,\quad x_2 = K_2^{-1}p_2 \\
\therefore x_2 &= R x_1 + t
\end{align}
$$

　　这里 $t$ 用了加法，所以比较碍事，我们试着通过叉乘来解决。

$$
\begin{align}
[t]_{\text{x}} x_2 &= [t]_{\text{x}} R x_1 + [t]_{\text{x}}t = [t]_{\text{x}} R x_1 \\
x_2^T [t]_{\text{x}} x_2 &= x_2^T [t]_{\text{x}} R x_1
\end{align}
$$

　　根据叉乘的几何意义可知 $x_2^T [t]_{\text{x}} x$ 为零。那么把 $x_2$ 的表达式代入到上式左侧，有：

$$
\begin{align}
(K_2^{-1}p_2)^T \cdot [t]_{\text{x}} R \cdot (K_1^{-1}p_1) = 0 \\
\therefore p_2^T \cdot K_2^{-T} [t]_{\text{x}} R K_1^{-1} \cdot p_1 = p_2^T \cdot F \cdot p_1 = 0 \\

F = K_2^{-T} \cdot [t]_{\text{x}} R \cdot K_1^{-1} = K_2^{-T} \cdot E \cdot K_1^{-1}, \quad E = [t]_{\text{x}} R
\end{align}
$$

# 3. 基础矩阵的求解

　　那么剩下的问题就是基础矩阵的求解了。最原始的思路还是通过解方程，把 $F$ 中 9 个参数设为未知数，带入 $p_2^T \cdot F \cdot p_1 = 0$ 中，展开后是一个混合着未知数 $f_i$ 和已知点对坐标 $(u_i, v_i, u_j, v_j)$ 的方程，把这个方程写成矩阵的形式 $A_{9 \times 9} F_{9 \times 1} = 0$ 。

　　一对点 $P_{1,2}$ 可以提供一个方程，那么理论上来说应该需要 9 对匹配点才能解这个方程。但是实际上，矩阵 $F$ 并不是满秩的，其实际变量只有 7 个，但是在实际应用中我们使用 8 对匹配点，称为八点法。但是接下来我们还是按照 9 个未知数求解。

$$
\begin{align}
[t]_{\text{x}} = \begin{bmatrix}
0 & -t_3 & t_2 \\
t_3 & 0 & -t_1 \\
-t_2 & t_1 & 0
\end{bmatrix} \Rightarrow \begin{bmatrix}
t_3 & 0 & -t_1 \\
0 & -t_3 & t_2 \\
0 & 0 & 0
\end{bmatrix}
\end{align}
$$

　　$F$ 不是满秩的，这点从上面 $[t]_{\text{x}}$ 就能看出来。通过对其做初等行变换，可见其秩为 2 ，不是满秩的，所以 $F$ 也不可能是满秩的。

　　那么如何解这个奇次方程呢？此方程可能有唯一解，也可能有无穷解（不稳定），需要使用 SVD 分解。

　　接下来我们讨论更一般的情况，设系数矩阵 $A_{m \times n}$ ，未知数矩阵 $X_{n \times 1}$ ，使用 SVD 分解求解这个方程。先对系数矩阵 $A$ 做 SVD 分解，然后把分解的结果代入方程中，其中 $\Sigma$ 是对角阵。

$$
\begin{align}
\begin{array}{c}
\because \quad SVD(A) = U \Sigma V^T \\
\therefore \quad AX = U \Sigma V^T X = 0
\end{array}
\end{align}
$$

　　由于方程很多时候是超定的情况，所以我们解方程是研究一个优化问题，**即未知数 X 取何值时，使 AX 的值尽可能小，这里的误差我们一般使用二范数（欧式距离）来衡量**。

　　令 $Y = V^T X$ ，则方程写成范数的形式有：$||U \Sigma V^T X|| = ||U \Sigma Y||$ 。因为矩阵 $U$ 是一个正交矩阵，所以其二范数为 1，所以 $||U \Sigma Y|| = ||\Sigma Y||$ 。接下来就是对这个式子进行化简，过程如下：

$$
\begin{align}
\because ||x|| &= x \cdot x^T \\
\therefore ||\Sigma Y|| &= Y^T \Sigma^T \Sigma Y = \begin{bmatrix}
y_1 & y_2 & \cdots & y_n
\end{bmatrix} \begin{bmatrix}
\sigma_1^2 &  &  & \\
  & \sigma_2^2 &  & \\
  &  & \ddots  & \\
  &  &  & \sigma_n^2
\end{bmatrix} \begin{bmatrix}
y_1 \\ y_2 \\ \vdots \\ y_n
\end{bmatrix} \\
&= \begin{bmatrix}
y_1 \sigma_1^2 &  &  & \\
  & y_2 \sigma_2^2 &  & \\
  &  & \ddots  & \\
  &  &  & y_n \sigma_n^2
\end{bmatrix} \begin{bmatrix}
y_1 \\ y_2 \\ \vdots \\ y_n
\end{bmatrix} = y_1^2 \sigma_1^2 + y_2^2 \sigma_2^2 + \cdots + y_n^2 \sigma_n^2 \\
\\
\therefore ||AX|| &= y_1^2 \sigma_1^2 + y_2^2 \sigma_2^2 + \cdots + y_n^2 \sigma_n^2
\end{align}
$$

　　为了得到最优解，我们引入两个前提：

* 未知数 $X$ 代表的 $F$ 一般我们会对其归一化，所以有 $||X||=1 \rightarrow ||Y|| = ||V^TX|| = 1$ 作为约束条件。
* 对于 $\sigma_i^2$ 是对角化的结果，满足由大到小的排列，所以 $\sigma_1 > \sigma_2 > \cdots > \sigma_n$ 。

　　在以上这两个条件约束下，$||AX||$ 的最优解存在于 $y_1 = y_2 = \cdots = y_{n-1} = 0, y_n = 1$ 时，此时 $||\Sigma Y||$ 有最小值。根据 $Y$ 的定义式可知，

$$
\begin{align}
\because &\ Y = V^T X, VV^T = E \\
\therefore & VY = X \\
\therefore & X = [v_1, v_2 \cdots v_n]_{n \times n} \begin{bmatrix}
0 \\ 0 \\ \vdots \\ 1
\end{bmatrix}_{n \times 1} = v_n
\end{align}
$$

　　所以，$X$ 的值就是 $V$ 的最后一列。

　　如果按照 9 个未知数来求解，会求出满秩的 $F$，此时会通过 SVD 分解的方法去掉一维，如下所示：

$$
\begin{align}
F = U \begin{bmatrix}
s_1 & 0 & 0 \\
0 & s_2 & 0 \\
0 & 0 & s_3
\end{bmatrix} V^T
\end{align}
$$

　　$s_{1,2,3}$ 是按照从大到小排列的，所以直接把 $s_3$ 舍去，令其为零。然后得到新的 $F'$ 作为新的结果。

# 4. 本质矩阵的分解

　　得到基础矩阵 $F$ 后，通过内参就能得到本质矩阵 $E$，但是本质矩阵的 $RT$ 是混在一起的，所以需要把他们分开。

　　首先引入 n 维反对称阵和矩阵 $W$ ，（至于为什么构造出矩阵 $W$ 原因未知）如下所示。

$$
\begin{align}
&\begin{bmatrix}
 0 & 1 &  &  &  &  &  & \\
 -1 & 0 &  &  &  &  &  & \\
  &  & 0 & 1 &  &  &  & \\
  &  & -1 & 0 &  &  &  & \\
  &  &  &  & 0 & 1 &  & \\
  &  &  &  & -1 & 0 &  & \\
  &  &  &  &  &  & \ddots & \\
  &  &  &  &  &  &  & \ddots  
\end{bmatrix} \\
Z &= \begin{bmatrix}
 0 & 1 & 0 \\
 -1 & 0 & 0 \\
 0 & 0 & 0
\end{bmatrix}
\\
W &= \begin{bmatrix}
 0 & -1 & 0 \\
 1 & 0 & 0 \\
 0 & 0 & 1
\end{bmatrix}
\end{align}
$$

　　我们这里是三维的，所以 n 维反对称阵只需要取前三行即可，我们记为矩阵 $Z$，同时把 $[t]_{\text{x}}$ 分解成 $a \cdot U \cdot Z \cdot U^T$ ，其中 $a$ 是一个常数。可以验证：

$$
\begin{align}
diag[1,1,0] \cdot W &= \begin{bmatrix}
 1 &  &  \\
 & 1 &  \\
 &  & 0
\end{bmatrix} \cdot Z^T = -Z; \\
diag[1,1,0] \cdot W^T &= Z
\end{align}
$$

　　使用 $W, W^T$ 的区别在于差了一个正负号，会影响最后该留下哪些外参，该舍去哪些。下面的推导中我们统一用 $W^{(T)}$ 来指代，先不区分。

　　把 $Z$ 的表达式代入到 $[t]_{\text{x}}$ 分解式子中，有：

$$
\begin{align}
E &= [t]_{\text{x}}R = a \cdot U \cdot Z \cdot U^T \cdot R\\
&= a \cdot U \cdot diag[1,1,0] \cdot W^{(T)} \cdot U^T \cdot R \\
&= a \cdot U \cdot \Lambda \cdot V^T
\end{align}
$$

　　上式中，$U$ 和 $W^{(T)} \cdot U^T \cdot R$ 是正交阵，记：$V^T = W^{(T)} \cdot U^T \cdot R$ 。这正是 $E$ 的 SVD 分解。所以就可以求出旋转矩阵 $R$：

$$
\begin{align}
R = U \cdot W^{(T)} \cdot V^T 
\end{align}
$$

　　一般来说，我们会在旋转矩阵前加入其行列式的值，写成 $det(R) \cdot R$ 。要求旋转矩阵的行列式要大于零，才有实际意义。

　　由于 $W^{(T)}$ 有两种情况，所以旋转矩阵和平移矩阵各有两种。我们要确保光轴在相机前方，判断 $RT$ 是否符合要求的方式有很多，比如直接代入 100 个点进行三角化（下一讲的内容），看哪一组 $RT$ 能确保大部分点在相机前，$E$ 的分解正因为有很多情况，所以不稳定。

　　
